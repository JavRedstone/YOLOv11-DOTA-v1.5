# -*- coding: utf-8 -*-
"""JavierH-YOLOv11-DOTA-v1.5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mb9WWhO9-k271FvuFEUB8LfRGbXbcCN-

# DOTA Aerial Object Detection - YOLOv11 Demo Project
By: Javier H.

Colab link: https://colab.research.google.com/drive/1mb9WWhO9-k271FvuFEUB8LfRGbXbcCN-?usp=sharing

---

This project demonstrates how to preprocess and train the [YOLOv11](https://docs.ultralytics.com/models/yolo11/) model on aerial imagery using sample data from the **DOTA v1.5** dataset.

## Dataset

- **DOTA** (Dataset for Object deTection in Aerial images): A large-scale benchmark for detecting oriented objects in aerial images.
- **Version**: v1.5 (used for demonstration; v2.0 is not in Google Drive); [Official site](https://captain-whu.github.io/DOTA/dataset.html)
- **Note**: YOLOv11 is typically trained on DOTA v1.0, but this project focuses more on **data transformation and preprocessing**, not benchmarking accuracy.

## Model

- **Model**: YOLOv11 Nano variant
- **Input Size**: 640×640 (default)

## Preprocessing & Data Transformation (Main Focus)

This project shows one of the processes I take to convert datasets into YOLO-compatible format, especially for datasets similar DOTA with oriented bounding boxes (OBB) or varying image resolution and sizes.

- **Tiling**: Images are split into overlapping tiles of 640×640 pixels (with black padding as needed)
- **Label Adjustment**:
  - Translates OBB annotations to fit each tile
  - Clamps bounding boxes to tile edges
  - Converts polygon OBBs to YOLO-oriented format (normalized coordinates)
  - Converts class names to integer indices
- **Why Tiling?**:
  - Prevents distortion from resizing non-square images
  - Preserves detail in high-resolution images
  - Improves detection of small, dense aerial objects

## Training

- Training is done using the transformed dataset
- Evaluation metrics, training logs, and visual results (e.g., predictions, confusion matrix, loss curves) are produced to monitor performance

This project focuses on **the process and pipeline** in training the YOLOv11 model.

## Experimentation

Experimentation is crucial in machine learning, so it is natural that there is trial and error present in the code. This is a Jupyter notebook after all. As a result, some cells have duplicate import statements due to running them individually for debugging purposes.

IMPORTANT: Do this installation first, otherwise the runtime will restart
"""

!pip install ultralytics

from google.colab import drive
drive.mount('/content/drive')

def check_gpu_availability():
    gpu_found = False

    # Check PyTorch
    try:
        import torch
        if torch.cuda.is_available():
            print(f"[PyTorch] GPU detected: {torch.cuda.get_device_name(0)}")
            gpu_found = True
        else:
            print("[PyTorch] No GPU detected. Running on CPU.")
    except ImportError:
        print("[PyTorch] Not installed.")

    # Check TensorFlow
    try:
        import tensorflow as tf
        gpus = tf.config.list_physical_devices('GPU')
        if gpus:
            print(f"[TensorFlow] GPU detected: {gpus[0].name}")
            gpu_found = True
        else:
            print("[TensorFlow] No GPU detected. Running on CPU.")
    except ImportError:
        print("[TensorFlow] Not installed.")

    if not gpu_found:
        print("No GPU found for either PyTorch or TensorFlow.")
check_gpu_availability()

import zipfile
import os

def extract_zip(zip_base_path, split_path, extract_base_path, extract_path):
    """
    Extracts a split ZIP file from Drive into Colab.
    """
    zip_path = os.path.join(zip_base_path, f"{split_path}.zip")
    extract_total_path = os.path.join(extract_base_path, extract_path)

    print(f"Extracting {zip_path}...")
    os.makedirs(extract_total_path, exist_ok=True)

    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_total_path)

    print(f"Extracted to: {extract_total_path}")
    return extract_total_path

"""## Location and File Storage

I added shortcuts from the DOTA v1.5 dataset Google Drive files to my own google drive at the `zip_base_path` location in the folders as seen in the dir variables. This is an amazing way to retain Google Drive space while being able to access the dataset which is already hosted in Google Drive.

Since this is a demonstration, I only extract the first part of training images. Feel free to train on a greater sample by extracting more images.
"""

zip_base_path = "/content/drive/MyDrive/Storage Bucket/ML/DOTA"
base_path = "/content/DOTA"

train_labels_dir = extract_zip(zip_base_path, "train/DOTA-v1.5_train", base_path, "train/labels")
train_images_dir = extract_zip(zip_base_path, "train/part1", base_path, "train") # No need for train/images as images is a folder within the extracted zip file
# train_images_dir = extract_zip(zip_base_path, "train/part2", base_path, "train")
# train_images_dir = extract_zip(zip_base_path, "train/part3", base_path, "train")
val_labels_dir = extract_zip(zip_base_path, "val/DOTA-v1.5_val", base_path, "val/labels")
val_images_dir = extract_zip(zip_base_path, "val/part1", base_path, "val")

# 80% train, 20% val
SAMPLE_TRAIN_IMAGES = 250 #@param {type:"slider", min:50, max:2000, step:50}
SAMPLE_VAL_IMAGES = 50   #@param {type:"slider", min:50, max:500, step:50}

import os
import shutil
import random

def sample_images_and_labels(
    image_src, label_src,
    image_dst, label_dst,
    num_samples
):
    """
    Sample images and  labels from source directories and copy them to destination directories.
    """

    os.makedirs(image_dst, exist_ok=True)
    os.makedirs(label_dst, exist_ok=True)

    # Clear previous files
    for f in os.listdir(image_dst): os.remove(os.path.join(image_dst, f))
    for f in os.listdir(label_dst): os.remove(os.path.join(label_dst, f))

    # Sample and copy
    all_images = [f for f in os.listdir(image_src) if f.endswith((".jpg", ".png", '.jpeg'))]
    sampled_images = random.sample(all_images, num_samples)
    print(str(len(all_images)) + " images found. Sampling " + str(num_samples) + " images...")

    for img in sampled_images:
        shutil.copy(os.path.join(image_src, img), os.path.join(image_dst, img))

        label_name = os.path.splitext(img)[0] + ".txt"
        label_src_path = os.path.join(label_src, label_name)
        if os.path.exists(label_src_path):
            shutil.copy(label_src_path, os.path.join(label_dst, label_name))

# Original dataset paths
train_img_dir = os.path.join(base_path, "train/images")
train_lbl_dir = os.path.join(base_path, "train/labels")
val_img_dir   = os.path.join(base_path, "val/images")
val_lbl_dir   = os.path.join(base_path, "val/labels")

# Sample output paths
sample_train_img = os.path.join(base_path, "sample_train_images")
sample_train_lbl = os.path.join(base_path, "sample_train_labels")
sample_val_img   = os.path.join(base_path, "sample_val_images")
sample_val_lbl   = os.path.join(base_path, "sample_val_labels")

# Run sampling
sample_images_and_labels(train_img_dir, train_lbl_dir, sample_train_img, sample_train_lbl, SAMPLE_TRAIN_IMAGES)
sample_images_and_labels(val_img_dir, val_lbl_dir, sample_val_img, sample_val_lbl, SAMPLE_VAL_IMAGES)

print("Sampled image/label sets created.")

import os
import random
import matplotlib.pyplot as plt
from PIL import Image

# Directories
dirs = {
    "Train Images": "/content/DOTA/sample_train_images",
    "Train Labels": "/content/DOTA/sample_train_labels",
    "Val Images": "/content/DOTA/sample_val_images",
    "Val Labels": "/content/DOTA/sample_val_labels",
}

# Count number of files in each directory
print("Sample Counts:")
for name, path in dirs.items():
    count = len([f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))])
    print(f"{name}: {count}")

def show_sample_image(image_dir):
    """
    Display one sample training image and print its size
    """
    image_files = [f for f in os.listdir(image_dir) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]
    if not image_files:
        print("No images found in:", image_dir)
        return None
    img_file = random.choice(image_files)
    img_path = os.path.join(image_dir, img_file)

    img = Image.open(img_path)
    width, height = img.size
    print(f"\nImage File: {img_file}")
    print(f"Size: {width} x {height}")

    plt.imshow(img)
    plt.title(f"Sample Train Image: {img_file}")
    plt.axis('off')
    plt.show()

    return img_file

def show_label(label_dir, image_filename):
    """
    Print matching label file
    """
    label_file = os.path.splitext(image_filename)[0] + ".txt"
    label_path = os.path.join(label_dir, label_file)

    print(f"\nLabel File: {label_file}")
    if os.path.exists(label_path):
        with open(label_path, 'r') as f:
            lines = f.readlines()
            if lines:
                print("Contents:")
                for line in lines:
                    print("  ", line.strip())
            else:
                print("  (Empty file)")
    else:
        print("  Label file not found.")

sample_image = show_sample_image(dirs["Train Images"])
if sample_image:
    show_label(dirs["Train Labels"], sample_image)

"""## DOTA Annotation Format

Source: https://captain-whu.github.io/DOTA/dataset.html

Each annotation file corresponds to an image and contains one object per line, using an Oriented Bounding Box (OBB):

### Annotation Line Format

```
x1, y1, x2, y2, x3, y3, x4, y4, category, difficult
```

| Field        | Description                                                    |
|--------------|----------------------------------------------------------------|
| x1, y1       | Top-left corner of the bounding box                            |
| x2, y2       | Top-right corner (clockwise order)                             |
| x3, y3       | Bottom-right corner                                            |
| x4, y4       | Bottom-left corner                                             |
| category     | Object class name (e.g., plane, ship, bridge, etc.)            |
| difficult    | 0 = easy, 1 = difficult to detect                               |

All coordinates define the four corners of a rotated rectangle in **clockwise order**.

---

### Object Categories by DOTA Version

| DOTA Version | Categories (cumulative)                                                           |
|--------------|------------------------------------------------------------------------------------|
| v1.0         | plane, ship, storage tank, baseball diamond, tennis court, basketball court, ground track field, harbor, bridge, large vehicle, small vehicle, helicopter, roundabout, soccer ball field, swimming pool |
| v1.5         | All of v1.0 + container crane                                                     |
| v2.0         | All of v1.5 + airport, helipad                                                    |

We are using DOTA v1.5 since DOTA v2.0 is not available in Google Drive.

---

### Metadata Format (First 3 Lines of Label File)

| Line Number | Field             | Description                                       |
|-------------|------------------|---------------------------------------------------|
| 1           | acquisition dates | Date the image was captured, or `None`           |
| 2           | imagesource       | Source of image (e.g., `GoogleEarth`, `GF-2`, `JL-1`) |
| 3           | gsd               | Ground Sample Distance in meters, or `None`      |
"""

def remove_metadata(label_path):
    """
    Removes metadata lines at the start of a DOTA label file.
    Metadata lines start with 'acquisition dates:', 'imagesource:', or 'gsd:'.
    Writes the cleaned content back to the same file.

    Args:
        label_path (str): Path to the label text file.
    """
    metadata_keys = {'acquisition dates:', 'imagesource:', 'gsd:'}
    cleaned_lines = []

    with open(label_path, 'r') as f:
        lines = f.readlines()

    # Skip metadata lines from the top
    idx = 0
    while idx < len(lines):
        line_lower = lines[idx].strip().lower()
        if any(line_lower.startswith(key) for key in metadata_keys):
            idx += 1
        else:
            break

    # Keep the rest of the lines
    cleaned_lines = lines[idx:]

    # Overwrite the file without metadata
    with open(label_path, 'w') as f:
        f.writelines(cleaned_lines)

import os
import math
from PIL import Image
import numpy as np

def tile_image_with_labels(
    image_path,
    label_path,
    output_img_dir,
    output_lbl_dir,
    tile_size=640,
    overlap=0.25
):
    """
    Tile an image and adjust its DOTA OBB labels accordingly.

    Parameters:
        image_path (str): Path to the original image.
        label_path (str): Path to the label text file.
        output_img_dir (str): Directory to save image tiles.
        output_lbl_dir (str): Directory to save adjusted labels.
        tile_size (int): Size of the square tile.
        overlap (float): Fraction of overlap (e.g., 0.25 = 25%).
    """
    os.makedirs(output_img_dir, exist_ok=True)
    os.makedirs(output_lbl_dir, exist_ok=True)

    img = Image.open(image_path).convert('RGB')
    img_w, img_h = img.size

    stride = int(tile_size * (1 - overlap))
    obb_data = []

    # Read original labels
    with open(label_path, 'r') as f:
        for line in f:
            parts = line.strip().split()
            coords = list(map(float, parts[:8]))
            cls = parts[8]
            difficult = parts[9]
            obb_data.append((coords, cls, difficult))

    tile_id = 0
    for y in range(0, img_h, stride):
        for x in range(0, img_w, stride):
            x_end = min(x + tile_size, img_w)
            y_end = min(y + tile_size, img_h)

            # Crop and pad image tile
            tile = img.crop((x, y, x_end, y_end))
            tile_w, tile_h = tile.size
            if tile_w < tile_size or tile_h < tile_size:
                padded_tile = Image.new('RGB', (tile_size, tile_size), (0, 0, 0))
                padded_tile.paste(tile, (0, 0))
                tile = padded_tile

            tile_filename = f"{os.path.splitext(os.path.basename(image_path))[0]}_{tile_id:04}.png"
            tile_path = os.path.join(output_img_dir, tile_filename)
            tile.save(tile_path)

            # Filter and adjust labels for this tile
            adjusted_labels = []
            for coords, cls, difficult in obb_data:
                coords_arr = np.array(coords).reshape(4, 2)
                min_x, min_y = coords_arr.min(axis=0)
                max_x, max_y = coords_arr.max(axis=0)

                if (max_x < x) or (min_x > x_end) or (max_y < y) or (min_y > y_end):
                    continue  # Completely outside

                # Translate and clamp coordinates
                shifted_coords = []
                for px, py in coords_arr:
                    new_x = px - x
                    new_y = py - y
                    new_x = min(max(new_x, 0), tile_size - 1)
                    new_y = min(max(new_y, 0), tile_size - 1)
                    shifted_coords.extend([new_x, new_y])

                adjusted_labels.append(" ".join(map(str, shifted_coords)) + f" {cls} {difficult}")

            # Save adjusted labels
            label_filename = tile_filename.replace(".png", ".txt")
            label_path_out = os.path.join(output_lbl_dir, label_filename)
            with open(label_path_out, 'w') as out_f:
                out_f.write("\n".join(adjusted_labels))

            tile_id += 1

    return tile_id

import glob
import os

def batch_tile_dataset(
    image_dir,
    label_dir,
    out_img_dir,
    out_lbl_dir,
    tile_size=640,
    overlap=0.25
):
    os.makedirs(out_img_dir, exist_ok=True)
    os.makedirs(out_lbl_dir, exist_ok=True)

    image_paths = glob.glob(os.path.join(image_dir, "*.*"))
    count_tiles = 0

    for img_path in image_paths:
        img_name = os.path.splitext(os.path.basename(img_path))[0]
        lbl_path = os.path.join(label_dir, img_name + ".txt")

        if not os.path.exists(lbl_path):
            print(f"Label not found for {img_name}, skipping.")
            continue

        # Remove metadata lines from label file before processing
        remove_metadata(lbl_path)

        n_tiles = tile_image_with_labels(
            img_path,
            lbl_path,
            out_img_dir,
            out_lbl_dir,
            tile_size=tile_size,
            overlap=overlap
        )
        count_tiles += n_tiles
        print(f"Processed {img_name}, created {n_tiles} tiles.")

    print(f"Total tiles created: {count_tiles}")

# batch_tile_dataset(
#     image_dir="/content/DOTA/sample_train_images",
#     label_dir="/content/DOTA/sample_train_labels_raw",
#     out_img_dir="/content/DOTA/tiles/train/images",
#     out_lbl_dir="/content/DOTA/tiles/train/labels_raw",
#     tile_size=640,
#     overlap=0.25
# )

# batch_tile_dataset(
#     image_dir="/content/DOTA/sample_val_images",
#     label_dir="/content/DOTA/sample_val_labels_raw",
#     out_img_dir="/content/DOTA/tiles/val/images",
#     out_lbl_dir="/content/DOTA/tiles/val/labels_raw",
#     tile_size=640,
#     overlap=0.25
# )

"""## Optimizing via multi-processing
The above is too slow to be used for large datasets. We instead try multi-processing and use a faster library (cv2)
"""

import numpy as np
import cv2
import os

def tile_image_with_labels_cv2(
    image_path,
    label_path,
    output_img_dir,
    output_lbl_dir,
    tile_size=640,
    overlap=0.25
):
    os.makedirs(output_img_dir, exist_ok=True)
    os.makedirs(output_lbl_dir, exist_ok=True)

    img = cv2.imread(image_path)
    img_h, img_w = img.shape[:2]

    stride = int(tile_size * (1 - overlap))

    obb_data = []
    with open(label_path, 'r') as f:
        for line in f:
            parts = line.strip().split()
            coords = list(map(float, parts[:8]))
            cls = parts[8]
            obb_data.append((coords, cls))

    tile_id = 0
    for y in range(0, img_h, stride):
        for x in range(0, img_w, stride):
            x_end = min(x + tile_size, img_w)
            y_end = min(y + tile_size, img_h)

            tile = img[y:y_end, x:x_end]

            # Pad if smaller than tile_size
            pad_bottom = tile_size - tile.shape[0]
            pad_right = tile_size - tile.shape[1]
            if pad_bottom > 0 or pad_right > 0:
                tile = cv2.copyMakeBorder(tile, 0, pad_bottom, 0, pad_right, cv2.BORDER_CONSTANT, value=[0,0,0])

            tile_filename = f"{os.path.splitext(os.path.basename(image_path))[0]}_{tile_id:04}.png"
            tile_path = os.path.join(output_img_dir, tile_filename)
            cv2.imwrite(tile_path, tile)

            adjusted_labels = []
            for coords, cls in obb_data:
                coords_arr = np.array(coords).reshape(4, 2)
                min_x, min_y = coords_arr.min(axis=0)
                max_x, max_y = coords_arr.max(axis=0)

                # Skip if polygon completely outside tile
                if (max_x < x) or (min_x > x_end) or (max_y < y) or (min_y > y_end):
                    continue

                shifted_coords = []
                for px, py in coords_arr:
                    # Shift to tile coords and clip
                    new_x = px - x
                    new_y = py - y
                    new_x = np.clip(new_x, 0, tile_size - 1)
                    new_y = np.clip(new_y, 0, tile_size - 1)
                    shifted_coords.extend([new_x, new_y])

                # Optional: check for polygon validity (e.g., minimum area or distinct points)
                # If invalid, skip
                pts = np.array(shifted_coords).reshape(4, 2)
                if np.linalg.matrix_rank(pts - pts[0]) < 2:
                    # Degenerate polygon, skip
                    continue

                adjusted_labels.append(" ".join(map(str, shifted_coords)) + f" {cls}")

            label_filename = tile_filename.replace(".png", ".txt")
            label_path_out = os.path.join(output_lbl_dir, label_filename)
            with open(label_path_out, 'w') as out_f:
                out_f.write("\n".join(adjusted_labels))

            tile_id += 1

    return tile_id

def process_single_image(args):
    img_path, lbl_path, out_img_dir, out_lbl_dir, tile_size, overlap = args

    if not os.path.exists(lbl_path):
        print(f"Label not found for {os.path.basename(img_path)}, skipping.")
        return 0

    remove_metadata(lbl_path)
    n_tiles = tile_image_with_labels_cv2(
        img_path, lbl_path, out_img_dir, out_lbl_dir, tile_size, overlap
    )
    print(f"Processed {os.path.basename(img_path)}, created {n_tiles} tiles.")
    return n_tiles

from multiprocessing import Pool, cpu_count

def batch_tile_dataset_parallel(
    image_dir,
    label_dir,
    out_img_dir,
    out_lbl_dir,
    tile_size=640,
    overlap=0.25,
    num_workers=None
):
    os.makedirs(out_img_dir, exist_ok=True)
    os.makedirs(out_lbl_dir, exist_ok=True)

    image_paths = glob.glob(os.path.join(image_dir, "*.*"))
    if num_workers is None:
        num_workers = max(1, cpu_count() - 1)

    args_list = []
    for img_path in image_paths:
        img_name = os.path.splitext(os.path.basename(img_path))[0]
        lbl_path = os.path.join(label_dir, img_name + ".txt")
        args_list.append((img_path, lbl_path, out_img_dir, out_lbl_dir, tile_size, overlap))

    with Pool(num_workers) as pool:
        results = pool.map(process_single_image, args_list)

    total_tiles = sum(results)
    print(f"Total tiles created: {total_tiles}")

TILE_SIZE = 640 #@param {type:"slider", min:320, max:1280, step:32}
TILE_OVERLAP = 0.25 #@param {type:"slider", min:0, max:1, step:0.05}

batch_tile_dataset_parallel(
    image_dir="/content/DOTA/sample_train_images",
    label_dir="/content/DOTA/sample_train_labels",
    out_img_dir="/content/DOTA/tiles/train/images",
    out_lbl_dir="/content/DOTA/tiles/train/labels_raw",
    tile_size=TILE_SIZE,
    overlap=TILE_OVERLAP
)

batch_tile_dataset_parallel(
    image_dir="/content/DOTA/sample_val_images",
    label_dir="/content/DOTA/sample_val_labels",
    out_img_dir="/content/DOTA/tiles/val/images",
    out_lbl_dir="/content/DOTA/tiles/val/labels_raw",
    tile_size=TILE_SIZE,
    overlap=TILE_OVERLAP
)

"""## Visualizing the tiles and the OBBs
Before converting to the OBB label format as required by YOLO, we can do a preliminary visualization of the tiles themselves and the OBBs on the labelled objects.

Update: We modify the methods after to allow visualization of the YOLO obb formats.
"""

# Class mapping
class_to_index = {
    "plane": 0,
    "ship": 1,
    "storage-tank": 2,
    "baseball-diamond": 3,
    "tennis-court": 4,
    "basketball-court": 5,
    "ground-track-field": 6,
    "harbor": 7,
    "bridge": 8,
    "large-vehicle": 9,
    "small-vehicle": 10,
    "helicopter": 11,
    "roundabout": 12,
    "soccer-ball-field": 13,
    "swimming-pool": 14,
    "container-crane": 15
}

# Reverse mapping
index_to_class = {v: k for k, v in class_to_index.items()}

def draw_obb(image, obbs, color=(0, 255, 0), thickness=2):
    """
    Draws oriented bounding boxes (OBBs) on an image.

    Args:
        image (np.ndarray): Input image.
        obbs (List[Tuple[str, List[Tuple[float, float]]]]): List of OBBs with class name and 4 points.
    """
    for class_name, points in obbs:
        pts = np.array(points, dtype=np.int32).reshape((-1, 1, 2))
        cv2.polylines(image, [pts], isClosed=True, color=color, thickness=thickness)
        x, y = int(points[0][0]), int(points[0][1])
        cv2.putText(image, class_name, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5,
                    (0, 255, 255), 1, cv2.LINE_AA)
    return image

def read_label_file(label_path, is_yolo=False, index_to_class=None, image_shape=None):
    """
    Reads a label file and returns oriented bounding boxes with class names.

    Args:
        label_path (str): Path to the label file.
        is_yolo (bool): Whether the label file is in YOLO format.
        index_to_class (dict): Mapping from class index to class name (for YOLO).
        image_shape (Tuple[int, int]): (height, width) of the image (required for YOLO format).

    Returns:
        List[Tuple[str, List[Tuple[float, float]]]]: (class_name, list of 4 points)
    """
    obbs = []

    with open(label_path, 'r') as f:
        for line in f:
            parts = line.strip().split()
            if len(parts) < 9:
                continue

            if is_yolo:
                if image_shape is None:
                    raise ValueError("image_shape must be provided for YOLO label decoding.")

                class_index = int(parts[0])
                coords = list(map(float, parts[1:9]))

                img_h, img_w = image_shape
                # Convert relative [0,1] to absolute coordinates
                abs_coords = [
                    (coords[i] * img_w, coords[i + 1] * img_h)
                    for i in range(0, 8, 2)
                ]
                class_name = index_to_class.get(class_index, f"class_{class_index}")
                obbs.append((class_name, abs_coords))
            else:
                coords = list(map(float, parts[:8]))
                points = [(coords[i], coords[i + 1]) for i in range(0, 8, 2)]
                class_name = parts[8]
                obbs.append((class_name, points))

    return obbs

def render_image_with_obbs(image_path, label_path, is_yolo=False, index_to_class=None):
    """
    Loads image and overlays oriented bounding boxes.

    Args:
        image_path (str): Path to image file.
        label_path (str): Path to label file.
        is_yolo (bool): Whether to interpret labels as YOLO format.
        index_to_class (dict): Mapping for YOLO format.

    Returns:
        np.ndarray: Image with OBBs drawn.
    """
    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    if os.path.exists(label_path):
        img_h, img_w = image.shape[:2]
        obbs = read_label_file(label_path, is_yolo=is_yolo, index_to_class=index_to_class, image_shape=(img_h, img_w))
        image = draw_obb(image, obbs)

    return image

def visualize_tiled_image_grid(
    tile_img_dir,
    tile_lbl_dir,
    tile_prefix=None,
    tile_size=640,
    cols=4,
    figsize=(16, 12),
    is_yolo=False,
    index_to_class=None
):
    """
    Displays tiled subimages with bounding boxes in a grid.

    Args:
        tile_img_dir (str): Directory containing the tiled images.
        tile_lbl_dir (str): Directory containing the tiled label files.
        tile_prefix (str): Prefix of the tiled files to match the original image.
        tile_size (int): Size of each tile (default is 640).
        cols (int): Number of columns in the tile grid.
        figsize (Tuple[int, int]): Size of the entire figure for the tile grid.
        is_yolo (bool): Whether the labels are in YOLO format.
        index_to_class (dict): Class index → name map for YOLO format.
    """
    tile_imgs = sorted(glob.glob(os.path.join(tile_img_dir, f"{tile_prefix}_*.png")))
    num_tiles = len(tile_imgs)
    rows = (num_tiles + cols - 1) // cols

    fig, axs = plt.subplots(rows, cols, figsize=figsize)
    axs = axs.flatten()

    for i, tile_path in enumerate(tile_imgs):
        tile_name = os.path.splitext(os.path.basename(tile_path))[0]
        label_path = os.path.join(tile_lbl_dir, tile_name + ".txt")

        tile_img = render_image_with_obbs(
            tile_path,
            label_path,
            is_yolo=is_yolo,
            index_to_class=index_to_class
        )

        axs[i].imshow(tile_img)
        axs[i].set_title(tile_name, fontsize=8)
        axs[i].axis('off')

    for j in range(i + 1, len(axs)):
        axs[j].axis('off')

    plt.tight_layout()
    plt.suptitle("Tiled Images with OBBs", fontsize=14, y=1.02)
    plt.show()

def visualize_sample_and_tiles(
    sample_name,
    image_path,
    label_path,
    tile_img_dir,
    tile_lbl_dir,
    is_yolo=False,
    index_to_class=None
):
    """
    Visualizes the original image and its tiles with OBBs.

    Args:
        sample_name (str): Name of the sample (no extension).
        image_path (str): Path to the image.
        label_path (str): Path to the label file.
        tile_img_dir (str): Directory with tiled images.
        tile_lbl_dir (str): Directory with tiled label files.
        is_yolo (bool): If using YOLO-format labels.
        index_to_class (dict): For YOLO class name decoding.
    """
    rendered = render_image_with_obbs(
        image_path,
        label_path,
        is_yolo=is_yolo,
        index_to_class=index_to_class
    )

    plt.figure(figsize=(8, 8))
    plt.title(f"Original Image: {sample_name}")
    plt.imshow(rendered)
    plt.axis('off')
    plt.show()

    visualize_tiled_image_grid(
        tile_img_dir=tile_img_dir,
        tile_lbl_dir=tile_lbl_dir,
        tile_prefix=sample_name,
        is_yolo=is_yolo,
        index_to_class=index_to_class
    )

def select_random_sample(train_img_dir, train_lbl_dir):
    """
    Randomly selects a sample image and label file from the dataset.

    Args:
        train_img_dir (str): Directory with training images.
        train_lbl_dir (str): Directory with corresponding label files.

    Returns:
        Tuple[str, str, str, str]: (sample_name, image_path, label_path, image_file_name)
    """
    image_files = [f for f in os.listdir(train_img_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
    if not image_files:
        raise FileNotFoundError("No training images found in the specified directory.")

    sample_file = random.choice(image_files)
    sample_name = os.path.splitext(sample_file)[0]

    image_path = os.path.join(train_img_dir, sample_file)
    label_path = os.path.join(train_lbl_dir, sample_name + ".txt")

    return sample_name, image_path, label_path, sample_file

sample_name, image_path, label_path, sample_file = select_random_sample(
    train_img_dir="/content/DOTA/sample_train_images",
    train_lbl_dir="/content/DOTA/sample_train_labels"
)

visualize_sample_and_tiles(
    sample_name=sample_name,
    image_path=image_path,
    label_path=label_path,
    tile_img_dir="/content/DOTA/tiles/train/images",
    tile_lbl_dir="/content/DOTA/tiles/train/labels_raw",
    is_yolo=False,
    index_to_class=index_to_class
)

"""## YOLO v11 OBB Data Format
https://docs.ultralytics.com/datasets/obb/

> The YOLO OBB format designates bounding boxes by their four corner points with coordinates normalized between 0 and 1. It follows this format:

```
class_index x1 y1 x2 y2 x3 y3 x4 y4
```
"""

import os
import cv2
import numpy as np

def convert_label_to_yolo_obb_format(src_label_path, dest_label_path, class_to_index, image_width, image_height):
    """
    Convert a label file polygon coords to YOLOv11 OBB polygon format:
    class_index x1 y1 x2 y2 x3 y3 x4 y4
    (all coordinates normalized to [0,1])

    Args:
        src_label_path (str): Path to source polygon label file.
        dest_label_path (str): Path to save YOLOv11 polygon format label.
        class_to_index (dict): Mapping from class name to integer index.
        image_width (int): Width of the image.
        image_height (int): Height of the image.
    """
    with open(src_label_path, 'r') as f:
        lines = f.readlines()

    yolo_lines = []
    for line in lines:
        parts = line.strip().split()
        if len(parts) < 9:
            continue

        coords = list(map(float, parts[:8]))
        class_name = parts[8]
        if class_name not in class_to_index:
            print(f"Warning: Unknown class '{class_name}' in {src_label_path}")
            continue

        class_index = class_to_index[class_name]

        # Normalize each coordinate
        normalized_coords = []
        for i in range(0, 8, 2):
            x_norm = coords[i] / image_width
            y_norm = coords[i+1] / image_height
            normalized_coords.extend([x_norm, y_norm])

        # Format line: class_index x1 y1 x2 y2 x3 y3 x4 y4
        yolo_line = f"{class_index} " + " ".join(f"{c:.6f}" for c in normalized_coords)
        yolo_lines.append(yolo_line)

    os.makedirs(os.path.dirname(dest_label_path), exist_ok=True)
    with open(dest_label_path, 'w') as f:
        f.write("\n".join(yolo_lines))

def convert_label_worker(args):
    src_label_path, dest_label_path, image_path, class_to_index = args

    if not os.path.exists(image_path):
        print(f"Warning: Image not found for {src_label_path}")
        return None

    image = cv2.imread(image_path)
    if image is None:
        print(f"Warning: Failed to load image {image_path}")
        return None

    height, width = image.shape[:2]
    convert_label_to_yolo_obb_format(src_label_path, dest_label_path, class_to_index, width, height)
    return os.path.basename(src_label_path)

def convert_labels_dataset_parallel(
    label_dir,
    yolo_label_dir,
    class_to_index,
    image_dir,
    image_ext=".png",
    num_workers=None
):
    """
    Convert all label files in label_dir to YOLOv11 OBB format in parallel.

    Args:
        label_dir (str): Directory with processed label files.
        yolo_label_dir (str): Output directory for YOLO formatted labels.
        class_to_index (dict): Mapping from class name to class index.
        image_dir (str): Directory containing corresponding images.
        image_ext (str): Image file extension (e.g., ".png", ".jpg").
        num_workers (int, optional): Number of parallel workers.
    """
    os.makedirs(yolo_label_dir, exist_ok=True)

    label_files = glob.glob(os.path.join(label_dir, "*.txt"))
    args_list = []
    for src_path in label_files:
        fname = os.path.basename(src_path)
        dest_path = os.path.join(yolo_label_dir, fname)
        image_name = os.path.splitext(fname)[0] + image_ext
        image_path = os.path.join(image_dir, image_name)
        args_list.append((src_path, dest_path, image_path, class_to_index))

    if num_workers is None:
        num_workers = max(1, cpu_count() - 1)

    total_converted = 0
    with Pool(num_workers) as pool:
        for result in pool.imap_unordered(convert_label_worker, args_list):
            if result is not None:
                print(f"Converted {result}")
                total_converted += 1

    print(f"Total labels converted: {total_converted}")

convert_labels_dataset_parallel(
    label_dir="/content/DOTA/tiles/train/labels_raw",
    yolo_label_dir="/content/DOTA/tiles/train/labels",
    class_to_index=class_to_index,
    image_dir="/content/DOTA/tiles/train/images",
    image_ext=".png"
)

convert_labels_dataset_parallel(
    label_dir="/content/DOTA/tiles/val/labels_raw",
    yolo_label_dir="/content/DOTA/tiles/val/labels",
    class_to_index=class_to_index,
    image_dir="/content/DOTA/tiles/val/images",
    image_ext=".png"
)

def count_files(dir_path, exts=('.png', '.jpg', '.jpeg', '.txt')):
    """
    Modularize file counting
    """
    if not os.path.exists(dir_path):
        return 0
    return len([f for f in os.listdir(dir_path) if f.lower().endswith(exts)])

def print_dataset_counts(base_path):
    splits = ['train', 'val']
    for split in splits:
        img_dir = os.path.join(base_path, split, 'images')
        lbl_dir = os.path.join(base_path, split, 'labels_raw')
        yolo_lbl_dir = os.path.join(base_path, split, 'labels')

        n_imgs = count_files(img_dir, exts=('.png', '.jpg', '.jpeg'))
        n_lbls = count_files(lbl_dir, exts=('.txt',))
        n_yolo = count_files(yolo_lbl_dir, exts=('.txt',))

        print(f"{split.upper()} dataset:")
        print(f"  Images: {n_imgs}")
        print(f"  Raw Labels: {n_lbls}")
        print(f"  YOLO Labels: {n_yolo}")
        print()

print_dataset_counts("/content/DOTA/tiles")

import yaml
import os

def generate_yolo_yaml(
    yaml_path,
    train_images_dir,
    val_images_dir,
    class_to_index,
    obb=True
):
    """
    Generate a YOLO dataset YAML file.

    Args:
        yaml_path (str): Output path for YAML file.
        train_images_dir (str): Path to training images.
        val_images_dir (str): Path to validation images.
        class_to_index (dict): Class name to index mapping.
        obb (bool): If True, include obb=True for YOLOv11 OBB support.
    """
    data = {
        'train': train_images_dir,
        'val': val_images_dir,
        'names': [None] * (max(class_to_index.values()) + 1)
    }

    for name, idx in class_to_index.items():
        data['names'][idx] = name

    if obb:
        data['obb'] = True

    os.makedirs(os.path.dirname(yaml_path), exist_ok=True)

    with open(yaml_path, 'w') as f:
        yaml.dump(data, f, default_flow_style=False)

    print(f"YOLO YAML saved to: {yaml_path}")

generate_yolo_yaml(
    yaml_path="/content/dota.yaml",
    train_images_dir="/content/DOTA/tiles/train/images",
    val_images_dir="/content/DOTA/tiles/val/images",
    class_to_index=class_to_index
)

"""## Model training

As stated in the introduction, this project focuses on the data transformation process. Of course, training for longer (more epochs; ultralytics recommends 300!) will allow for better results (e.g. mAP), but this is a demonstration of the workflow so it is not necessary.
"""

NUM_EPOCHS = 20 #@param {type:"slider", min:1, max:50, step:1}
BATCH_SIZE = 32 #@param {type:"slider", min:2, max:512, step:8}
NUM_WORKERS = 8 #@param {type:"slider", min:1, max:16, step:1}
SAVE_PERIOD = 5 #@param {type:"slider", min:1, max:20, step:1}
PATIENCE = 3 #@param {type:"slider", min:1, max:20, step:1}

import os
from ultralytics import YOLO, settings

settings.tensorboard = True

model = YOLO("yolo11n.pt")

model.train(
    data='/content/dota.yaml',
    epochs=NUM_EPOCHS,
    imgsz=TILE_SIZE,
    batch=BATCH_SIZE,
    workers=NUM_WORKERS,
    patience=PATIENCE,
    device='cuda',
    project=os.path.join(zip_base_path, 'yolo_runs'),
    name='obb_exp',
    save_period=SAVE_PERIOD,
    exist_ok=True,
    keras=True,
    seed=42
)

"""## Results

# Saved Results
"""

import os
import pandas as pd
import matplotlib.pyplot as plt
from IPython.display import display, Image, Markdown

runs_path = os.path.join(zip_base_path, 'yolo_runs', 'obb_exp')

# Display results.csv as a DataFrame
csv_path = os.path.join(runs_path, 'results.csv')
df = pd.read_csv(csv_path)
display(df)

# Plot key metrics from results.csv
plt.figure(figsize=(12, 5))

# Plot losses
plt.subplot(1, 2, 1)
plt.plot(df['epoch'], df['train/box_loss'], label='Box Loss')
plt.plot(df['epoch'], df['train/cls_loss'], label='Cls Loss')
plt.plot(df['epoch'], df['train/dfl_loss'], label='DFL Loss')
plt.title('Training Losses')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)

# Plot evaluation metrics
plt.subplot(1, 2, 2)
plt.plot(df['epoch'], df['metrics/precision(B)'], label='Precision')
plt.plot(df['epoch'], df['metrics/recall(B)'], label='Recall')
plt.plot(df['epoch'], df['metrics/mAP50(B)'], label='mAP@50')
plt.plot(df['epoch'], df['metrics/mAP50-95(B)'], label='mAP@50-95')
plt.title('Validation Metrics')
plt.xlabel('Epoch')
plt.ylabel('Score')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# Image captions
image_labels = {
    'BoxF1_curve.png': 'Box-Level F1 Score Curve',
    'BoxPR_curve.png': 'Precision-Recall Curve',
    'BoxP_curve.png': 'Box-Level Precision Curve',
    'BoxR_curve.png': 'Box-Level Recall Curve',
    'confusion_matrix.png': 'Raw Confusion Matrix',
    'confusion_matrix_normalized.png': 'Normalized Confusion Matrix',
    'labels.jpg': 'Training Label Distribution',
    'labels_correlogram.jpg': 'Label Co-occurrence Matrix',
    'results.png': 'YOLOv11 Training Summary Graph',
    'train_batch0.jpg': 'Train Batch 0 - Labels',
    'train_batch1.jpg': 'Train Batch 1 - Labels',
    'train_batch2.jpg': 'Train Batch 2 - Labels',
    'val_batch0_labels.jpg': 'Validation Batch 0 - Ground Truth',
    'val_batch0_pred.jpg': 'Validation Batch 0 - Predictions',
    'val_batch1_labels.jpg': 'Validation Batch 1 - Ground Truth',
    'val_batch1_pred.jpg': 'Validation Batch 1 - Predictions',
    'val_batch2_labels.jpg': 'Validation Batch 2 - Ground Truth',
    'val_batch2_pred.jpg': 'Validation Batch 2 - Predictions',
}

# Display output images with labels
for img_name in image_labels:
    img_path = os.path.join(runs_path, img_name)
    if os.path.exists(img_path):
        display(Markdown(f"### {image_labels[img_name]}"))
        display(Image(filename=img_path))
    else:
        print(f'Not found: {img_name}')

"""It is clear that with only 20 epochs, there is room for improvement as the mAP scores are consistenty increasing. All graphs for the results of this experiment are shown above, including side-by-side comparisons of ground truth and prediction annotated image batches."""

